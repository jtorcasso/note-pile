\documentclass{article}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage[left=2.5cm,right=2.5cm]{geometry}

\linespread{1.5}
\title{Notes on Continuous Treatment Effects}
\author{Jake C. Torcasso}
\begin{document}
	
	\section{Introduction}
	We want to understand the impact of a treatment $T$ on an outcome
	$Y$. In particular, we wish to compare the outcome at two counterfactual 
	treatment states, $T=t_1$ and $T=t_0$. These counterfactual outcomes can
	be written as $Y_t = Y(T=t)$, which is the outcome of $Y$ when 
	$T$ is \emph{fixed} at $t$. 

	To understand this notion of fixing we must
	introduce the vector $\mathcal{X}=(X,U)$, which contains all other observed ($X$)
	and unobserved ($U$) data which effect $Y$. 
	For use later, we denote $\mathcal{Z}$ as all other data which is independent of
	$Y$. 
	The idea of fixing is purely hypothetical. 
	When we fix $T=t$ we do so \emph{independently} of $\mathcal{X}$. Thus, the best
	way of understanding fixing is to understand when it is equivalent to
	statistical conditioning. If $T \perp \mathcal{X}$, 
	then $Y_t \,{\buildrel d \over =}\,  Y|T$ and likewise, if $T\not\perp X$, 
	but $T\perp U$, then $Y_t|X \,{\buildrel d \over =}\, Y|X,T$. 
	This assumption of \emph{full independence} will allow identification of a class
	of treatment effects. We will see that identification of the mean treatment
	effect requires a less restrictive assumption.

	\section{Identification}
	Now we state the object of interest, namely, the mean treatment effect from
	changing $T=t_0$ to $T=t_1$.

	\begin{align}
		E[Y_{t_1} - Y_{t_0}] & = \int_x\int_uf_{U,X}(u,x)E[Y_{t_1}-Y_{t_0}|X=x,U=u]dudx \\ \nonumber
		                     & = \int_x\int_uf_{U,X}(u,x)\bigg(E[Y|T=t_1,X=x,U=u]-E[Y|T=t_0,X=x,U=u]\bigg)dudx
	\end{align}

	\noindent One can see quite easily the result of \emph{mean independence} between 
	$Y|T=t,X=x$ and $U$. To be explicit, when we have:

	\begin{equation} \tag{\textbf{A.1}} \label{eq:ass1}
		E[Y|T=t,X=x,U=u] = E[Y|T=t,X=x]
	\end{equation}

	\noindent Then the treatment effect becomes:

	\begin{align}
		& \int_x\int_uf_{U,X}(u,x)\bigg(E[Y|T=t_1,X=x]-E[Y|T=t_0,X=x]\bigg)dudx \\ \nonumber
		& = \int_xf_{X}(x)\bigg(E[Y|T=t_1,X=x]-E[Y|T=t_0,X=x]\bigg)dx
	\end{align}
	
	\noindent , which we can readily identify from the data. However, assumption \ref{eq:ass1}
	is too strong, especially when valid exclusion restrictions exist in $\mathcal{Z}$. 
	For instance, let $Z \subset \mathcal{Z}$ be a set of exclusion restrictions such that
	$Z \not\perp T$, but $Z \perp U$. If $rank(Z) \geq rank(T)$, then we can identify
	$E[Y_{t_1}-Y_{t_0}|X=x]$ using instrumental variable methods or the generalized
	propensity score.

\end{document}